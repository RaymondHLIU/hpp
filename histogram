// Histogram Equalization

#include    <wb.h>

#define HISTOGRAM_LENGTH 256
#define BLOCK_SIZE 256
#define wbCheck(stmt) do {                                                    \
        cudaError_t err = stmt;                                               \
        if (err != cudaSuccess) {                                             \
            wbLog(ERROR, "Failed to run stmt ", #stmt);                       \
            wbLog(ERROR, "Got CUDA error ...  ", cudaGetErrorString(err));    \
            return -1;                                                        \
        }                                                                     \
    } while(0)

//@@ insert code here
__global__ void castChar(float * input, unsigned char * output, int len){

	int i = blockDim.x * blockIdx.x + threadIdx.x;
	
	if(i < len)
		output[i] = (unsigned char) 255 * input[i];
}
	
__global__ void RGBtoGrayScale(unsigned char * input, unsigned char * output, int len){

	int i = blockDim.x * blockIdx.x + threadIdx.x;
	
	if(i < len){
	
		float r = input[3 * i];
		float g = input[3 * i + 1];
		float b = input[3 * i + 2];
		output[i] = (unsigned char) (0.21 * r + 0.71 * g + 0.07 * b);
	}
}

__global__ void histogram_kernel(unsigned char * input, unsigned int * histo, long size){

	__shared__ unsigned int histo_private[HISTOGRAM_LENGTH];
	if(threadIdx.x < HISTOGRAM_LENGTH) 
		histo_private[threadIdx.x] = 0;
	__syncthreads();
	int i = threadIdx.x + blockIdx.x*blockDim.x;
	// stride is total number of threads
	int stride = blockDim.x*gridDim.x;
	while(i < size){	
		atomicAdd(&(histo_private[input[i]]), 1);
		i += stride;
	}	
	__syncthreads();

	if (threadIdx.x < HISTOGRAM_LENGTH)
	{
		atomicAdd(&(histo[threadIdx.x]),histo_private[threadIdx.x]);
	}
}

__global__ void computeCDF(unsigned int * input, float * output, int norm, int len){

	unsigned int t = threadIdx.x;
	unsigned int start = 2*blockIdx.x*blockDim.x;

	__shared__ float result[BLOCK_SIZE*2];	
	// Load input into shared memory
	result[t]			 = ((start + t) < len) ? (float) (input[start + t]) / norm : 0;
	result[blockDim.x+t] = ((start + blockDim.x + t) < len) ? (float) (input[start + blockDim.x+t]) / norm : 0;
	__syncthreads();
	 
	// Reduction phase
	for (int stride = 1; stride <= BLOCK_SIZE; stride *= 2) {
		int index = (t + 1) * stride * 2 - 1;
		if (index < 2*BLOCK_SIZE) {
			result[index] += result[index - stride];
		}
		__syncthreads();
	}
	 
	// Post reduction reverse phase
	for (int stride = BLOCK_SIZE/2; stride > 0; stride /= 2) {
		__syncthreads();
		int index = (t + 1) * stride * 2 - 1;
		if (index + stride < 2*BLOCK_SIZE) {
			result[index + stride] += result[index];
		}
	
	}

	__syncthreads();
	if (start + t < len) {
		output[start + t] = result[t];
		if (start + BLOCK_SIZE + t < len) {
			output[start + BLOCK_SIZE + t] = result[BLOCK_SIZE + t];
		}
	}
}

__global__ void minCDF(float * input, float * output, int len) {
        
	__shared__ float partialSum[2*BLOCK_SIZE];
	unsigned int t = threadIdx.x;
	unsigned int start = 2*blockIdx.x*blockDim.x;
	
	//@@ Load a segment of the input vector into shared memory
	partialSum[t] = ((start + t) < len) ? input[start + t] : 0;
	partialSum[blockDim.x+t] = ((start + blockDim.x + t) < len) ? input[start + blockDim.x+t] : 0;

	//@@ Traverse the reduction tree
	for (unsigned int stride = blockDim.x; stride > 0;  stride /= 2) {
		__syncthreads();
		if (t < stride) {
			partialSum[t] = min(partialSum[t], partialSum[t+stride]);
		}
	}
	
	//@@ Write the computed sum of the block to the output vector at the 
    //@@ correct index
	if (t == 0) output[blockIdx.x] = partialSum[0];
}

__global__ void equalize(unsigned char  *input, float *cdf, float *cdfmin, int len) {
	int i = blockDim.x * blockIdx.x + threadIdx.x;

	if (i < len) {
		input[i] = min(max(255*(cdf[input[i]] - cdfmin[0])/(1 - cdfmin[0]), 0.0), 255.0);		
	}
}

	
__global__ void castFloat(unsigned char  *input, float *output, int len) {
	int i = blockDim.x * blockIdx.x + threadIdx.x;

	if (i < len) {
		output[i] = (float) (input[i]/255.0);
	}
}

int main(int argc, char ** argv) {
    wbArg_t args;
    int imageWidth;
    int imageHeight;
    int imageChannels;
    wbImage_t inputImage;
    wbImage_t outputImage;
    float * hostInputImageData;
    float * hostOutputImageData;
    const char * inputImageFile;

    //@@ Insert more code here
	float * deviceInputImageData;
	unsigned char * deviceCharImageData;
	unsigned char * deviceGrayImageData;
	unsigned int * deviceHistogram;
	float * deviceCDF;
	float * deviceMinCDF;
    float * deviceOutputImageData;

    args = wbArg_read(argc, argv); /* parse the input arguments */

    inputImageFile = wbArg_getInputFile(args, 0);

    wbTime_start(Generic, "Importing data and creating memory on host");
    inputImage = wbImport(inputImageFile);
    imageWidth = wbImage_getWidth(inputImage);
    imageHeight = wbImage_getHeight(inputImage);
    imageChannels = wbImage_getChannels(inputImage);
    outputImage = wbImage_new(imageWidth, imageHeight, imageChannels);
	hostInputImageData = wbImage_getData(inputImage);
	hostOutputImageData = wbImage_getData(outputImage);
    wbTime_stop(Generic, "Importing data and creating memory on host");

    //@@ insert code here
	int imageSize = imageWidth * imageHeight * imageChannels;
	int imageSizeGray = imageWidth * imageHeight;

	cudaMalloc((void **) &deviceInputImageData, imageSize * sizeof(float));
    cudaMalloc((void **) &deviceOutputImageData, imageSize * sizeof(float));
	cudaMalloc((void **) &deviceCharImageData, imageSize * sizeof(unsigned char));
    cudaMalloc((void **) &deviceGrayImageData, imageSizeGray * sizeof(unsigned char));
	cudaMalloc((void **) &deviceHistogram, HISTOGRAM_LENGTH * sizeof(unsigned int));
	cudaMalloc((void **) &deviceCDF, HISTOGRAM_LENGTH * sizeof(float));
	cudaMalloc((void **) &deviceMinCDF, 1 * sizeof(float));
	
	cudaMemcpy(deviceInputImageData, hostInputImageData, imageSize * sizeof(float), cudaMemcpyHostToDevice);
	dim3 dimGrid((imageSize - 1)/BLOCK_SIZE + 1, 1, 1);
	dim3 dimBlock(BLOCK_SIZE, 1, 1);
	castChar<<<dimGrid, dimBlock>>>(deviceInputImageData, deviceCharImageData, imageSize);
    RGBtoGrayScale<<<dimGrid, dimBlock>>>(deviceCharImageData, deviceGrayImageData, imageSizeGray);
	histogram_kernel<<<dimGrid, dimBlock>>>(deviceGrayImageData, deviceHistogram, imageSizeGray);
	computeCDF<<<dimGrid, dimBlock>>>(deviceHistogram, deviceCDF, imageSizeGray, HISTOGRAM_LENGTH);
	minCDF<<<1, HISTOGRAM_LENGTH>>>(deviceCDF, deviceMinCDF, HISTOGRAM_LENGTH);
	equalize<<<dimGrid, dimBlock>>>(deviceCharImageData, deviceCDF, deviceMinCDF, imageSize);
	castFloat<<<dimGrid, dimBlock>>>(deviceCharImageData, deviceOutputImageData, imageSize);
	cudaDeviceSynchronize();
	
	
	cudaMemcpy(hostOutputImageData, deviceOutputImageData, imageSize * sizeof(float), cudaMemcpyDeviceToHost);
    wbSolution(args, outputImage);

    //@@ insert code here
	cudaFree(deviceInputImageData);
    cudaFree(deviceOutputImageData);
    cudaFree(deviceCharImageData);
	cudaFree(deviceGrayImageData);
	cudaFree(deviceCDF);
	cudaFree(deviceMinCDF);
	cudaFree(deviceHistogram);

    return 0;
}


